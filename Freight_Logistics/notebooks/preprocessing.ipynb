{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting complete data preprocessing pipeline...\n",
      "Directory '../data/raw' created or already exists\n",
      "Directory '../data/processed' created or already exists\n",
      "Directory '../models' created or already exists\n",
      "Directory '../results' created or already exists\n",
      "Data loaded successfully with shape: (20000, 11)\n",
      "Data loaded and cleaned successfully\n",
      "\n",
      "Created new features:\n",
      "Time-based: ['Planned_Delivery_Days', 'Actual_Delivery_Days', 'Delay_Days']\n",
      "Date-based: ['Shipment_Month', 'Shipment_Day_Of_Week', 'Is_Weekend', 'Shipment_Quarter']\n",
      "Distance-based: ['Distance_Category', 'Avg_Speed', 'Is_Long_Distance']\n",
      "Weather/Traffic: ['Is_Bad_Weather', 'Is_Heavy_Traffic']\n",
      "Feature engineering complete\n",
      "\n",
      "Data Analysis:\n",
      "\n",
      "Basic Statistics:\n",
      "        Shipment_ID  Distance_(km)       Delayed  Planned_Delivery_Days  \\\n",
      "count  20000.000000   20000.000000  20000.000000           20000.000000   \n",
      "mean    9999.500000    1101.663750      0.737850               3.269400   \n",
      "std     5773.647028     520.717873      0.439815               1.734928   \n",
      "min        0.000000     200.000000      0.000000               1.000000   \n",
      "25%     4999.750000     649.750000      0.000000               2.000000   \n",
      "50%     9999.500000    1102.000000      1.000000               3.000000   \n",
      "75%    14999.250000    1551.000000      1.000000               5.000000   \n",
      "max    19999.000000    2000.000000      1.000000              13.000000   \n",
      "\n",
      "       Actual_Delivery_Days    Delay_Days  Shipment_Month  \\\n",
      "count          20000.000000  20000.000000    20000.000000   \n",
      "mean               5.205050      1.935650        5.464750   \n",
      "std                2.584151      2.044289        3.388323   \n",
      "min                1.000000     -9.000000        1.000000   \n",
      "25%                3.000000      0.000000        3.000000   \n",
      "50%                5.000000      1.000000        5.000000   \n",
      "75%                7.000000      3.000000        8.000000   \n",
      "max               16.000000     10.000000       12.000000   \n",
      "\n",
      "       Shipment_Day_Of_Week   Is_Weekend  Shipment_Quarter     Avg_Speed  \\\n",
      "count           20000.00000  20000.00000      20000.000000  20000.000000   \n",
      "mean                2.99650      0.28230          2.175350    236.381989   \n",
      "std                 1.99321      0.45013          1.096432     99.812833   \n",
      "min                 0.00000      0.00000          1.000000     20.909091   \n",
      "25%                 1.00000      0.00000          1.000000    163.800000   \n",
      "50%                 3.00000      0.00000          2.000000    233.000000   \n",
      "75%                 5.00000      1.00000          3.000000    303.600000   \n",
      "max                 6.00000      1.00000          4.000000    599.000000   \n",
      "\n",
      "       Is_Long_Distance  Is_Bad_Weather  Is_Heavy_Traffic  \n",
      "count      20000.000000    20000.000000      20000.000000  \n",
      "mean           0.499550        0.302400          0.153600  \n",
      "std            0.500012        0.459309          0.360574  \n",
      "min            0.000000        0.000000          0.000000  \n",
      "25%            0.000000        0.000000          0.000000  \n",
      "50%            0.000000        0.000000          0.000000  \n",
      "75%            1.000000        1.000000          0.000000  \n",
      "max            1.000000        1.000000          1.000000  \n",
      "\n",
      "Delay Analysis:\n",
      "Delay Rate: 0.73785\n",
      "\n",
      "Vehicle Type Distribution:\n",
      "Lorry        0.251404\n",
      "Truck        0.250477\n",
      "Trailer      0.249343\n",
      "Container    0.248776\n",
      "Name: Vehicle_Type, dtype: float64\n",
      "\n",
      "Weather Conditions Distribution:\n",
      "Clear    0.69760\n",
      "Rain     0.15335\n",
      "Fog      0.10070\n",
      "Storm    0.04835\n",
      "Name: Weather_Conditions, dtype: float64\n",
      "\n",
      "Traffic Conditions Distribution:\n",
      "Light       0.4975\n",
      "Moderate    0.3489\n",
      "Heavy       0.1536\n",
      "Name: Traffic_Conditions, dtype: float64\n",
      "\n",
      "Encoded Origin with 10 unique values\n",
      "Mapping: {'Ahmedabad': 0, 'Bangalore': 1, 'Chennai': 2, 'Delhi': 3, 'Hyderabad': 4, 'Jaipur': 5, 'Kolkata': 6, 'Lucknow': 7, 'Mumbai': 8, 'Pune': 9}\n",
      "\n",
      "Encoded Destination with 10 unique values\n",
      "Mapping: {'Ahmedabad': 0, 'Bangalore': 1, 'Chennai': 2, 'Delhi': 3, 'Hyderabad': 4, 'Jaipur': 5, 'Kolkata': 6, 'Lucknow': 7, 'Mumbai': 8, 'Pune': 9}\n",
      "\n",
      "Encoded Vehicle_Type with 5 unique values\n",
      "Mapping: {'Container': 0, 'Lorry': 1, 'Trailer': 2, 'Truck': 3, nan: 4}\n",
      "\n",
      "Encoded Weather_Conditions with 4 unique values\n",
      "Mapping: {'Clear': 0, 'Fog': 1, 'Rain': 2, 'Storm': 3}\n",
      "\n",
      "Encoded Traffic_Conditions with 3 unique values\n",
      "Mapping: {'Heavy': 0, 'Light': 1, 'Moderate': 2}\n",
      "\n",
      "Encoded Distance_Category with 5 unique values\n",
      "Mapping: {'Long': 0, 'Medium': 1, 'Short': 2, 'Very_Long': 3, 'Very_Short': 4}\n",
      "Categorical encoding complete\n",
      "\n",
      "Data split complete:\n",
      "Training set size: 16000\n",
      "Testing set size: 4000\n",
      "Feature preparation complete\n",
      "\n",
      "Files saved successfully:\n",
      "- Processed data: data/processed/processed_data.csv\n",
      "- Train/test splits: data/processed/X_train.csv, X_test.csv, y_train.csv, y_test.csv\n",
      "- Encoders and scaler: models/label_encoders.pkl, models/scaler.pkl\n",
      "- Feature columns: models/feature_columns.txt\n",
      "\n",
      "Preprocessing pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_directories():\n",
    "    \"\"\"\n",
    "    Create necessary directories if they don't exist\n",
    "    \"\"\"\n",
    "    directories = [\n",
    "        '../data/raw',\n",
    "        '../data/processed',\n",
    "        '../models',\n",
    "        '../results'\n",
    "    ]\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"Directory '{directory}' created or already exists\")\n",
    "\n",
    "def load_and_clean_data(filepath='../data/raw/freight_log.csv'):\n",
    "    \"\"\"\n",
    "    Load and perform initial cleaning of the freight data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV data\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Clean column names\n",
    "        df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
    "        \n",
    "        # Convert date columns to datetime\n",
    "        date_columns = ['Shipment_Date', 'Planned_Delivery_Date', 'Actual_Delivery_Date']\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "        \n",
    "        # Extract numeric part from Shipment_ID and convert to integer\n",
    "        df['Shipment_ID'] = df['Shipment_ID'].str.extract('(\\d+)').astype(int)\n",
    "        \n",
    "        print(f\"Data loaded successfully with shape: {df.shape}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create new features from existing data\n",
    "    \"\"\"\n",
    "    # Time-based features\n",
    "    df['Planned_Delivery_Days'] = (df['Planned_Delivery_Date'] - df['Shipment_Date']).dt.days\n",
    "    df['Actual_Delivery_Days'] = (df['Actual_Delivery_Date'] - df['Shipment_Date']).dt.days\n",
    "    df['Delay_Days'] = df['Actual_Delivery_Days'] - df['Planned_Delivery_Days']\n",
    "    \n",
    "    # Date features\n",
    "    df['Shipment_Month'] = df['Shipment_Date'].dt.month\n",
    "    df['Shipment_Day_Of_Week'] = df['Shipment_Date'].dt.dayofweek\n",
    "    df['Is_Weekend'] = df['Shipment_Day_Of_Week'].isin([5, 6]).astype(int)\n",
    "    df['Shipment_Quarter'] = df['Shipment_Date'].dt.quarter\n",
    "    \n",
    "    # Distance-based features\n",
    "    df['Distance_Category'] = pd.qcut(df['Distance_(km)'], q=5, \n",
    "                                    labels=['Very_Short', 'Short', 'Medium', 'Long', 'Very_Long'])\n",
    "    df['Avg_Speed'] = df['Distance_(km)'] / df['Actual_Delivery_Days']\n",
    "    df['Is_Long_Distance'] = (df['Distance_(km)'] > df['Distance_(km)'].median()).astype(int)\n",
    "    \n",
    "    # Weather and traffic impact\n",
    "    df['Is_Bad_Weather'] = df['Weather_Conditions'].isin(['Rain', 'Storm', 'Fog']).astype(int)\n",
    "    df['Is_Heavy_Traffic'] = (df['Traffic_Conditions'] == 'Heavy').astype(int)\n",
    "    \n",
    "    # Convert target variable to numeric\n",
    "    df['Delayed'] = (df['Delayed'] == 'Yes').astype(int)\n",
    "    \n",
    "    print(\"\\nCreated new features:\")\n",
    "    print(\"Time-based:\", ['Planned_Delivery_Days', 'Actual_Delivery_Days', 'Delay_Days'])\n",
    "    print(\"Date-based:\", ['Shipment_Month', 'Shipment_Day_Of_Week', 'Is_Weekend', 'Shipment_Quarter'])\n",
    "    print(\"Distance-based:\", ['Distance_Category', 'Avg_Speed', 'Is_Long_Distance'])\n",
    "    print(\"Weather/Traffic:\", ['Is_Bad_Weather', 'Is_Heavy_Traffic'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def encode_categorical_variables(df):\n",
    "    \"\"\"\n",
    "    Encode categorical variables for model input\n",
    "    \"\"\"\n",
    "    # Initialize dictionary to store label encoders\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Columns to encode\n",
    "    categorical_columns = [\n",
    "        'Origin', 'Destination', 'Vehicle_Type',\n",
    "        'Weather_Conditions', 'Traffic_Conditions',\n",
    "        'Distance_Category'\n",
    "    ]\n",
    "    \n",
    "    # Encode each categorical column\n",
    "    for col in categorical_columns:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        df[col] = label_encoders[col].fit_transform(df[col])\n",
    "        print(f\"\\nEncoded {col} with {len(label_encoders[col].classes_)} unique values\")\n",
    "        mapping = dict(zip(label_encoders[col].classes_, label_encoders[col].transform(label_encoders[col].classes_)))\n",
    "        print(f\"Mapping: {mapping}\")\n",
    "    \n",
    "    return df, label_encoders\n",
    "\n",
    "def prepare_features_for_modeling(df):\n",
    "    \"\"\"\n",
    "    Prepare final feature set for modeling\n",
    "    \"\"\"\n",
    "    # Select features for modeling\n",
    "    feature_columns = [\n",
    "        'Distance_(km)', 'Distance_Category', \n",
    "        'Shipment_Month', 'Shipment_Day_Of_Week', \n",
    "        'Shipment_Quarter', 'Is_Weekend',\n",
    "        'Planned_Delivery_Days', 'Actual_Delivery_Days', \n",
    "        'Delay_Days', 'Avg_Speed', 'Is_Long_Distance',\n",
    "        'Is_Bad_Weather', 'Is_Heavy_Traffic',\n",
    "        'Origin', 'Destination', 'Vehicle_Type',\n",
    "        'Weather_Conditions', 'Traffic_Conditions'\n",
    "    ]\n",
    "    \n",
    "    # Split features and target\n",
    "    X = df[feature_columns]\n",
    "    y = df['Delayed']\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "    X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    \n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split complete:\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Testing set size: {len(X_test)}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, feature_columns, scaler\n",
    "\n",
    "def save_processed_data(df, X_train, X_test, y_train, y_test, label_encoders, feature_columns, scaler):\n",
    "    \"\"\"\n",
    "    Save all processed data and metadata\n",
    "    \"\"\"\n",
    "    # Save processed data\n",
    "    df.to_csv('../data/processed/processed_data.csv', index=False)\n",
    "    X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "    X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "    y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "    y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "    \n",
    "    # Save encoders and scaler\n",
    "    import joblib\n",
    "    joblib.dump(label_encoders, '../models/label_encoders.pkl')\n",
    "    joblib.dump(scaler, '../models/scaler.pkl')\n",
    "    \n",
    "    # Save feature columns\n",
    "    with open('models/feature_columns.txt', 'w') as f:\n",
    "        f.write('\\n'.join(feature_columns))\n",
    "    \n",
    "    print(\"\\nFiles saved successfully:\")\n",
    "    print(\"- Processed data: data/processed/processed_data.csv\")\n",
    "    print(\"- Train/test splits: data/processed/X_train.csv, X_test.csv, y_train.csv, y_test.csv\")\n",
    "    print(\"- Encoders and scaler: models/label_encoders.pkl, models/scaler.pkl\")\n",
    "    print(\"- Feature columns: models/feature_columns.txt\")\n",
    "\n",
    "def analyze_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic data analysis\n",
    "    \"\"\"\n",
    "    print(\"\\nData Analysis:\")\n",
    "    print(\"\\nBasic Statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nDelay Analysis:\")\n",
    "    print(\"Delay Rate:\", (df['Delayed'] == 1).mean())\n",
    "    \n",
    "    print(\"\\nVehicle Type Distribution:\")\n",
    "    print(df['Vehicle_Type'].value_counts(normalize=True))\n",
    "    \n",
    "    print(\"\\nWeather Conditions Distribution:\")\n",
    "    print(df['Weather_Conditions'].value_counts(normalize=True))\n",
    "    \n",
    "    print(\"\\nTraffic Conditions Distribution:\")\n",
    "    print(df['Traffic_Conditions'].value_counts(normalize=True))\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main preprocessing pipeline\n",
    "    \"\"\"\n",
    "    print(\"Starting complete data preprocessing pipeline...\")\n",
    "    \n",
    "    # Create necessary directories\n",
    "    create_directories()\n",
    "    \n",
    "    # Load and clean data\n",
    "    df = load_and_clean_data()\n",
    "    print(\"Data loaded and cleaned successfully\")\n",
    "    \n",
    "    # Create new features\n",
    "    df = create_features(df)\n",
    "    print(\"Feature engineering complete\")\n",
    "    \n",
    "    # Analyze data\n",
    "    analyze_data(df)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df, label_encoders = encode_categorical_variables(df)\n",
    "    print(\"Categorical encoding complete\")\n",
    "    \n",
    "    # Prepare features for modeling\n",
    "    X_train, X_test, y_train, y_test, feature_columns, scaler = prepare_features_for_modeling(df)\n",
    "    print(\"Feature preparation complete\")\n",
    "    \n",
    "    # Save all processed data\n",
    "    save_processed_data(df, X_train, X_test, y_train, y_test, label_encoders, feature_columns, scaler)\n",
    "    print(\"\\nPreprocessing pipeline completed successfully!\")\n",
    "    \n",
    "    return df, X_train, X_test, y_train, y_test, feature_columns, label_encoders, scaler\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df, X_train, X_test, y_train, y_test, feature_columns, label_encoders, scaler = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
